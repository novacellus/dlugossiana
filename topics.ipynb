{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76116577-120e-49d2-947c-8534c0f56982",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data imports\n",
    "import pickle\n",
    "with open(\"corpora/corpus_chapters\", \"rb\") as f:\n",
    "    corpus_chapters = pickle.load(f)\n",
    "with open(\"corpora/corpus_chapters_lemmas\", \"rb\") as f:\n",
    "    corpus_chapters_lemmas = pickle.load(f)\n",
    "with open(\"corpora/corpus_chapters_lemmas_reduced\", \"rb\") as f:\n",
    "    corpus_chapters_lemmas_reduced = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bbeefb2-2bd9-4e13-bb39-5009f6434dd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rebuild = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86f16f67-161f-4fa3-b804-9ee303444f93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prepare gensim model\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "if rebuild == True:\n",
    "    corpus_chapters_dictionary = corpora.Dictionary(corpus_chapters)\n",
    "    corpus_chapters_lemmas_dictionary = corpora.Dictionary(corpus_chapters_lemmas)\n",
    "    corpus_chapters_lemmas_bow =  [corpus_chapters_lemmas_dictionary.doc2bow(chapter) \n",
    "                          for chapter in corpus_chapters_lemmas]\n",
    "\n",
    "    # Set training parameters.\n",
    "    num_topics = range(10,100,10)\n",
    "    chunksize = 2000\n",
    "    passes = 20\n",
    "    iterations = 400\n",
    "    eval_every = None  # Don't evaluate model perplexity, takes too much time.\n",
    "\n",
    "    corpus_chapters_lemmas_dictionary.filter_extremes(no_below=5, no_above=0.5)\n",
    "    corpus_chapters_lemmas_bow =  [corpus_chapters_lemmas_dictionary.doc2bow(chapter) \n",
    "                          for chapter in corpus_chapters_lemmas]\n",
    "\n",
    "    corpus_chapters_lemmas_reduced_dictionary = corpora.Dictionary(corpus_chapters_lemmas_reduced)\n",
    "    corpus_chapters_lemmas_reduced_bow =  [corpus_chapters_lemmas_reduced_dictionary.doc2bow(chapter) \n",
    "                          for chapter in corpus_chapters_lemmas_reduced]\n",
    "    #Doc2Vec\n",
    "    corpus_chapters_lemmas_tagged = []\n",
    "    for i, chapter in enumerate(corpus_chapters_lemmas):\n",
    "        corpus_chapters_lemmas_tagged.append(TaggedDocument(chapter,[i]))\n",
    "    doc2vec_model = Doc2Vec()\n",
    "    doc2vec_model.build_vocab(corpus_chapters_lemmas_tagged)\n",
    "    doc2vec_model.train(corpus_chapters_lemmas_tagged, total_examples=doc2vec_model.corpus_count, epochs=80)\n",
    "    #pprint.pprint(dir(doc2vec_model))\n",
    "    #for vec in doc2vec_model.docvecs:\n",
    "    #    print(vec)\n",
    "    #Similarity()\n",
    "    doc2vec_model.save(\"models/doc2vec_model.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12114b5e-f3fe-430e-bedd-703a49e8582f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if rebuild == False:\n",
    "    doc2vec_model = Doc2Vec.load(\"models/doc2vec_model.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "139b0cd6-b75d-44d0-a2fd-6708dc892999",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "doc2vec_sim_dict = {}\n",
    "for doc1 in range(0,2862):\n",
    "    doc2vec_sim_dict[doc1] = []\n",
    "    for doc2 in range(0,2862):\n",
    "        #Iprint(doc1,doc2,doc2vec_model.dv.similarity(doc1,doc2))\n",
    "        doc2vec_sim_dict[doc1].append(doc2vec_model.dv.similarity(doc1,doc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da25342e-f03f-4224-8325-bce68e1b924a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if rebuild == True:\n",
    "    doc2vec_sim_df = pd.DataFrame.from_dict(doc2vec_sim_dict)\n",
    "    doc2vec_sim_df.head()\n",
    "    doc2vec_sim_df.to_pickle(\"doc2vec_sim_df.df\")\n",
    "else:\n",
    "    doc2vec_sim_df = pd.read_pickle(\"models/doc2vec_sim_df.df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13edff51-1d67-4b8c-870f-77a02b288129",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DOTAD UPORZADKOWANE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39138a32-71cf-4784-8d4e-239749e702db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39      0.489837\n",
      "2596    0.441823\n",
      "44      0.429102\n",
      "178     0.426119\n",
      "1192    0.419025\n",
      "251     0.385512\n",
      "611     0.367943\n",
      "1252    0.365028\n",
      "762     0.355356\n",
      "2256    0.354491\n",
      "Name: 1, dtype: float32\n"
     ]
    }
   ],
   "source": [
    "#top similar\n",
    "print(doc2vec_sim_df[1].nlargest(11)[1:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00ecbebe-76dd-434c-8ecd-0066158927a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'most_similar_docs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmost_similar_docs\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'most_similar_docs' is not defined"
     ]
    }
   ],
   "source": [
    "most_similar_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0478a4e9-e64b-433f-ac1d-bccfcb6e527a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "most_similar_docs = {}\n",
    "for i in doc2vec_sim_df.index:\n",
    "    if i not in most_similar_docs.keys():\n",
    "        most_similar_docs[i] = {}\n",
    "    largest_i = list(doc2vec_sim_df[i].nlargest(11).index)\n",
    "    #print(largest_i)\n",
    "    #most_similar_docs[i] = dict.fromkeys(largest_i, {\"year\":'', \"head\":'',\"text\":''})\n",
    "    #print(most_similar_docs[i])\n",
    "    year = ''\n",
    "    head = ''\n",
    "    text = ''\n",
    "    for n_i in largest_i:\n",
    "        #print(n_i)        \n",
    "        try:\n",
    "            year = search_text_chapter(n_i, \"year\")\n",
    "            \n",
    "        except Exception:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            head = search_text_chapter(n_i, \"head\")\n",
    "        except Exception:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            text = search_text_chapter(n_i, \"text\")\n",
    "        except Exception:\n",
    "            pass\n",
    "        \n",
    "        #print(year)\n",
    "        if n_i not in most_similar_docs[i].keys():\n",
    "            most_similar_docs[i][n_i]={\"year\":None,\"head\":None,\"text\":None}\n",
    "            most_similar_docs[i][n_i][\"year\"] = year\n",
    "            most_similar_docs[i][n_i][\"head\"] = head\n",
    "            most_similar_docs[i][n_i][\"text\"] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f77e652-aad2-4c09-be03-15ff4e9d4efd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1110: {'year': '', 'head': '', 'text': ''},\n",
       " 1098: {'year': '', 'head': '', 'text': ''},\n",
       " 2349: {'year': '', 'head': '', 'text': ''},\n",
       " 1106: {'year': '', 'head': '', 'text': ''},\n",
       " 956: {'year': '', 'head': '', 'text': ''},\n",
       " 1498: {'year': '', 'head': '', 'text': ''},\n",
       " 2309: {'year': '', 'head': '', 'text': ''},\n",
       " 1463: {'year': '', 'head': '', 'text': ''},\n",
       " 2505: {'year': '', 'head': '', 'text': ''},\n",
       " 2525: {'year': '', 'head': '', 'text': ''},\n",
       " 1520: {'year': '', 'head': '', 'text': ''}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar_docs[1110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9e205b9-65c0-41c0-ae68-2a2506f732f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#for liber in [2]:\u001b[39;00m\n\u001b[1;32m      5\u001b[0m tmp \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m liber \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtext_dict\u001b[49m\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chapter \u001b[38;5;129;01min\u001b[39;00m text_dict[liber]\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m      8\u001b[0m         chapter_tokens \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'text_dict' is not defined"
     ]
    }
   ],
   "source": [
    "docs_by_year = [] \n",
    "docs_by_liber = []\n",
    "docs_by_chapter = [] # list of chapters (liber, chapter, year, tokens)\n",
    "#for liber in [2]:\n",
    "tmp = []\n",
    "for liber in text_dict.keys():\n",
    "    for chapter in text_dict[liber].keys():\n",
    "        chapter_tokens = []\n",
    "        for txt_arr in text_dict[liber][chapter]:\n",
    "            #txt_arr_toks = []\n",
    "            if txt_arr[1] == \"text\": #exclude head etc.   \n",
    "                #print(txt_arr)\n",
    "                for tok in txt_arr[2]: #iterates over tokens                    \n",
    "                    chapter_tokens.append((liber, chapter, txt_arr[0], tok[0], tok[1], tok[2])) #liber,chap, year,token\n",
    "            else:\n",
    "                tmp.append(txt_arr)            \n",
    "                \n",
    "        if len(chapter_tokens) > 0:\n",
    "            docs_by_chapter.append(chapter_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f57fac53-4272-4371-9980-37b0212a8fe6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'search_text_chapter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msearch_text_chapter\u001b[49m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'search_text_chapter' is not defined"
     ]
    }
   ],
   "source": [
    "search_text_chapter(1,'year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3118e240-073c-43d2-91ac-ac05809d1b30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_to_all_chapters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#search_text_chapter(2,\"head\")\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtext_to_all_chapters\u001b[49m[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m      3\u001b[0m text_dict_joined[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m2\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'text_to_all_chapters' is not defined"
     ]
    }
   ],
   "source": [
    "#search_text_chapter(2,\"head\")\n",
    "text_to_all_chapters[2]\n",
    "text_dict_joined[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e731e769-2b99-486f-a4da-847fe8652214",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1029, 236, 2381, 461, 123, 1330, 595, 174, 730, 2026]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(doc2vec_sim_df[0].nlargest(11).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b0856f3-cbe7-4526-a669-2b7f80d5ea3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1.000000\n",
       "1029    0.562609\n",
       "236     0.556832\n",
       "2381    0.554758\n",
       "461     0.546207\n",
       "123     0.541571\n",
       "1330    0.541421\n",
       "595     0.535762\n",
       "174     0.526044\n",
       "730     0.516737\n",
       "2026    0.507058\n",
       "Name: 0, dtype: float32"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2vec_sim_df[0].nlargest(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7648b66b-f99d-4244-907a-1aabb9869b0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mrebuildn index tonlargestctionary.\n",
    "temp = corpus_chapters_lemmas_reduced_dictionary[0]  # This is only to \"load\" the dictionary.\n",
    "id2word = corpus_chapters_lemmas_reduced_dictionary.id2token\n",
    "\n",
    "lda_model_lemmas_reduced = LdaModel(\n",
    "    corpus=corpus_chapters_lemmas_reduced_bow,\n",
    "    id2word=id2word,\n",
    "    chunksize=chunksize,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=20,\n",
    "    passes=passes,\n",
    "    eval_every=eval_every\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64f5142b-e494-439e-a65c-7de06cc60fe8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyLDAvis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyLDAvis\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyLDAvis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgensim_models\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgensimvis\u001b[39;00m\n\u001b[1;32m      3\u001b[0m pyLDAvis\u001b[38;5;241m.\u001b[39menable_notebook()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyLDAvis'"
     ]
    }
   ],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = gensimvis.prepare(lda_model_lemmas_reduced, corpus_chapters_lemmas_reduced_bow, corpus_chapters_lemmas_reduced_dictionary)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f582a21d-2403-4bcd-969b-9edc82336436",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lda_model_lemmas_reduced' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m chapters_topic_dists \u001b[38;5;241m=\u001b[39m{}\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, chapter \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mlda_model_lemmas_reduced\u001b[49m\u001b[38;5;241m.\u001b[39mget_document_topics(corpus_chapters_lemmas_reduced_bow)):\n\u001b[1;32m      4\u001b[0m     chapters_topic_dists[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m\u001b[38;5;241m.\u001b[39mfromkeys(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m20\u001b[39m),\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m topic, prob \u001b[38;5;129;01min\u001b[39;00m chapter:        \n",
      "\u001b[0;31mNameError\u001b[0m: name 'lda_model_lemmas_reduced' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "chapters_topic_dists ={}\n",
    "for i, chapter in enumerate(lda_model_lemmas_reduced.get_document_topics(corpus_chapters_lemmas_reduced_bow)):\n",
    "    chapters_topic_dists[i] = dict.fromkeys(range(0,20),0)\n",
    "    for topic, prob in chapter:        \n",
    "        chapters_topic_dists[i][topic] = prob\n",
    "#print(chapters_topic_dists)\n",
    "chapters_topic_matrix = pd.DataFrame.from_dict(chapters_topic_dists,orient=\"index\")\n",
    "chapters_topic_matrix.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b58923b1-ea07-4cc4-8179-1cc235201f14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chapters_topic_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mchapters_topic_matrix\u001b[49m\u001b[38;5;241m.\u001b[39mplot()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'chapters_topic_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "chapters_topic_matrix.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e685ca3-21cb-4061-956b-05665cd6446e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.express as px\n",
    "chapters_topic_matrix[\"doc\"] = chapters_topic_matrix.index\n",
    "chapters_topic_matrix_years = { doc:year for doc, year in enumerate(corpus_chapters_lemmas_year) }\n",
    "chapters_topic_matrix[\"year\"] = corpus_chapters_lemmas_year\n",
    "chapters_topic_matrix.head()\n",
    "chapters_topic_matrix_wide = chapters_topic_matrix.melt(id_vars=[\"doc\",\"year\"],var_name=\"topic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30d6091-56ed-4f68-a7bf-84bdcf127586",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(corpus_chapters_lemmas_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e62bfc0-6206-46a9-ac25-71609263471f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chapters_topic_matrix_wide = chapters_topic_matrix_wide[chapters_topic_matrix_wide[\"value\"] > 0].sort_values([\"doc\",\"topic\"])\n",
    "chapters_topic_matrix_wide.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce51bf8-2784-4e65-ba28-2aa68eb060d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#px.scatter_matrix(chapters_topic_matrix, x=\"doc\", y=\"value\", color=topic)\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "fig = px.scatter(chapters_topic_matrix_wide[chapters_topic_matrix_wide[\"value\"] >0.5], x=\"doc\", y=\"value\",\n",
    "                 color=\"topic\",\n",
    "                 #size=\"value\",\n",
    "                 facet_col=\"topic\", facet_col_wrap=2, height=2000)\n",
    "#fig.update_layout(yaxis_range=[0.2,1.2])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8b8ca3-bef7-4e18-bd5f-22665588f143",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#px.scatter_matrix(chapters_topic_matrix, x=\"doc\", y=\"value\", color=topic)\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "fig = px.scatter(chapters_topic_matrix_wide[chapters_topic_matrix_wide[\"value\"] >0.3], x=\"year\",\n",
    "                 y=\"value\",\n",
    "                 color=\"topic\",\n",
    "                 #size=\"value\",\n",
    "                 facet_col=\"topic\", facet_col_wrap=2, height=2000)\n",
    "#fig.update_layout(yaxis_range=[0.2,1.2])\n",
    "fig.update_xaxes(categoryorder='array', categoryarray= corpus_chapters_lemmas_year)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d16c5c-f321-47bc-84de-59d66a2b195d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "topic_sims = []\n",
    "\n",
    "for similarities in index:\n",
    "    topic_sims.append(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a722087-4afd-4c08-9746-ee71a9a75288",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chapters_topic_sim = pd.DataFrame(topic_sims)\n",
    "chapters_topic_sim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d92a714-80d4-40a8-8cb4-0341cb792d27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for row in topic_matrix:\n",
    "    print(topic_matrix[row] > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a139934-033b-4390-847e-ed76f174bbbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for num_topic in num_topics:\n",
    "    lda_model_lemmas_rednlargested = LdaModel(\n",
    "        corpus=corpus_chapters_lemmas_reduced_bow,\n",
    "        id2word=id2word,\n",
    "        chunksize=chunksize,\n",
    "        alpha='auto',\n",
    "        eta='auto',\n",
    "        iterations=iterations,\n",
    "        num_topics=num_topic,\n",
    "        passes=passes,\n",
    "        eval_every=eval_every\n",
    "    )\n",
    "    coherence_model_lda = CoherenceModel(model=lda_model_lemmas_reduced, texts=corpus_chapters_lemmas_reduced, \n",
    "                                         dictionary=corpus_chapters_lemmas_reduced_dictionary,\n",
    "                                         coherence='c_v')\n",
    "    \n",
    "    print(\"topics: \" + str(num_topic) ,\"coherence: \", coherence_model_lda.get_coherence(), \n",
    "          \"\\tperplexity: \", \n",
    "          lda_model_lemmas_reduced.log_perplexity(corpus_chapters_lemmas_reduced_bow)\n",
    "         )\n",
    "#best results\n",
    "#topics: 10 coherence:  0.4043357272535478 \tperplexity:  -7.509568616109219\n",
    "#topics: 20 coherence:  0.45175391591224745 \tperplexity:  -7.559552059787899\n",
    "#topics: 30 coherence:  0.4145315890018234 \tperplexity:  -7.603553920253678\n",
    "#topics: 40 coherence:  0.41797913503984957 \tperplexity:  -7.663085551756763\n",
    "#topics: 50 coherence:  0.3995843728274568 \tperplexity:  -7.728750670838585"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7818b2-2957-4e06-b146-d959986c4833",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "coherence_model_lda = CoherenceModel(model=lda_model_lemmas_reduced, texts=corpus_chapters_lemmas_reduced, \n",
    "                                     dictionary=corpus_chapters_lemmas_reduced_dictionary,\n",
    "                                     coherence='c_v')\n",
    "\n",
    "print(\"topics: \" + str(20) ,\"coherence: \", coherence_model_lda.get_coherence(), \n",
    "      \"\\tperplexity: \", \n",
    "      lda_model_lemmas_reduced.log_perplexity(corpus_chapters_lemmas_reduced_bow)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439cf782-f516-4a1e-a33c-42f4c0f21569",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = gensimvis.prepare(lda_model_lemmas_reduced, corpus_chapters_lemmas_reduced_bow, corpus_chapters_lemmas_reduced_dictionary)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9220ee35-7403-44b4-b214-99c72adc49f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corpus_chapters_lemmas_dictionary.filter_extremes(no_below=5, no_above=0.5)\n",
    "corpus_chapters_lemmas_bow =  [corpus_chapters_lemmas_dictionary.doc2bow(chapter) \n",
    "                      for chapter in corpus_chapters_lemmas\n",
    "                              ]\n",
    "\n",
    "# Make an index to word dictionary.\n",
    "temp = corpus_chapters_lemmas_dictionary[0]  # This is only to \"load\" the dictionary.\n",
    "id2word = corpus_chapters_lemmas_dictionary.id2token\n",
    "\n",
    "for num_topic in num_topics:\n",
    "    lda_model_lemmas = LdaModel(\n",
    "        corpus=corpus_chapters_lemmas_bow,\n",
    "        id2word=id2word,\n",
    "        chunksize=chunksize,\n",
    "        alpha='auto',\n",
    "        eta='auto',\n",
    "        iterations=iterations,\n",
    "        num_topics=num_topic,\n",
    "        passes=passes,\n",
    "        eval_every=eval_every\n",
    "    )\n",
    "    coherence_model_lda = CoherenceModel(model=lda_model_lemmas, texts=corpus_chapters_lemmas, \n",
    "                                         dictionary=corpus_chapters_lemmas_dictionary,\n",
    "                                         coherence='c_v')\n",
    "    \n",
    "    print(\"topics: \" + str(num_topic) ,\"coherence: \", coherence_model_lda.get_coherence(), \"\\tperplexity: \", \n",
    "          lda_model_lemmas.log_perplexity(corpus_chapters_lemmas_bow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bdaabe-95ca-4ebd-ad32-91e2dd3d86a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.probability import ConditionalFreqDist\n",
    "word_len_cfd = ConditionalFreqDist()\n",
    "chapter_len_cfd = ConditionalFreqDist()\n",
    "year_len_cfd = ConditionalFreqDist()\n",
    "liber_len_cfd = ConditionalFreqDist()\n",
    "chapters_nltk_categorized.fileids()\n",
    "chapters_word_length = {\"by_year\" : {}, \"by_chapter\" : {}, \"by_liber\" : {}}\n",
    "for file in chapters_nltk_categorized.fileids():\n",
    "    file_id = re.sub(r'\\.txt', '', file)\n",
    "    #print(file_id)\n",
    "    #print(search_text_chapter(int(file_id), \"year\"))\n",
    "    year = search_text_chapter(int(file_id), \"year\")\n",
    "    chapter = search_text_chapter(int(file_id), \"chapter\")\n",
    "    liber = search_text_chapter(int(file_id), \"liber\")\n",
    "    #word_lens = []\n",
    "    for w in chapters_nltk_categorized.words(file):\n",
    "        if w not in [';', ',', '.', '-', '\"', '?', '!']:\n",
    "            word_len_cfd[len(w)][w] +=1\n",
    "            chapter_len_cfd[chapter][len(w)] +=1\n",
    "            year_len_cfd[year][len(w)] +=1\n",
    "            liber_len_cfd[liber][len(w)] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ae8b3d-0b84-4ce5-9918-aac6525db393",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# topic modelling\n",
    "# Train LDA model.\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "# Set training parameters.\n",
    "num_topics = 10\n",
    "chunksize = 2000\n",
    "passes = 20\n",
    "iterations = 400\n",
    "eval_every = None  # Don't evaluate model perplexity, takes too much time.\n",
    "\n",
    "# Make an index to word dictionary.\n",
    "temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
    "id2word = dictionary.id2token\n",
    "\n",
    "model = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    chunksize=chunksize,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=num_topics,\n",
    "    passes=passes,\n",
    "    eval_every=eval_every\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac21494-3074-4694-844e-88e7b5c7daff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
