{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0410bc0d-95d8-4552-9353-b97e8f21082c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from lxml import etree\n",
    "import gensim\n",
    "#read the corpus\n",
    "src_file = os.path.join('src/DLUG_Ann_clean.vrt')\n",
    "tree = etree.parse(src_file)\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8c06ddb-55fc-4c08-8596-fcccfd4e0562",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#check type of text block\n",
    "def check_type(div):\n",
    "    typeof = 'text'  #p div etc\n",
    "    if div.tag == \"head\":\n",
    "        if \"class\" in div.attrib.keys():\n",
    "            if div.attrib[\"class\"] == \"annus\":\n",
    "                typeof='annus'\n",
    "            elif div.attrib[\"class\"] == \"chapter\":\n",
    "                typeof='chapter'\n",
    "            else:\n",
    "                typeof=\"head\"\n",
    "        else:\n",
    "                typeof=\"head\"                \n",
    "    return typeof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfd01a41-595a-4259-a9d2-b8a9583f2a9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_vrt(raw):\n",
    "    lines = []\n",
    "    for line in [line for line in raw.split(\"\\n\") if line != \"\"]:\n",
    "        tok,pos,lem = None, None, None\n",
    "        cols = line.split('\\t')\n",
    "        if len(cols) == 3:\n",
    "            tok, pos,lem = cols\n",
    "        else:\n",
    "            tok = cols[0]\n",
    "        lines.append((tok,pos,lem))\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "710b562a-a299-423a-b669-c5351d57be3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_dict = {}\n",
    "#text_dict = {book : {chapter : [{year, typeof, txt}]} }\n",
    "liber = 0\n",
    "for el in root: #liber\n",
    "    year = 0\n",
    "    chapter = None\n",
    "    classes = ['head', 'annus', 'text']\n",
    "    typeof = 'text'\n",
    "    raw_text = ''\n",
    "    \n",
    "    #liber\n",
    "    if \"class\" in el.attrib.keys():\n",
    "        if el.attrib[\"class\"] == 'liber':\n",
    "            liber = int(el.attrib[\"n\"])\n",
    "            text_dict[liber] = dict()\n",
    "            #print(\"liber\",liber)\n",
    "    for ell in el.getchildren():\n",
    "        if \"class\" in el.attrib.keys():\n",
    "            if ell.attrib[\"class\"] == \"year\":\n",
    "                year = ell.attrib[\"n\"]\n",
    "                #print(\"year \", year)\n",
    "                for elll in ell.getchildren():\n",
    "                    if elll.tag == \"head\":\n",
    "                        typeof = check_type(elll)                \n",
    "                        raw_text = elll.text\n",
    "                        \n",
    "                        if chapter is not None:\n",
    "                            chapter += 1\n",
    "                        else:\n",
    "                            chapter = 0\n",
    "                        \n",
    "                        text_dict[liber][chapter] = list()\n",
    "                        text_dict[liber][chapter].append([year, typeof, process_vrt(raw_text)])\n",
    "                            \n",
    "                    elif elll.tag == \"div\":\n",
    "                        if elll.attrib[\"class\"] == \"chapter\":\n",
    "                            if chapter is not None:\n",
    "                                chapter += 1\n",
    "                            else:\n",
    "                                chapter = 0\n",
    "                            #print(\"chapter \", chapter)\n",
    "                            text_dict[liber][chapter] = list()\n",
    "                            for ellll in elll.getchildren():\n",
    "                                typeof = check_type(ellll)\n",
    "                                raw_text = ellll.text\n",
    "                                #print(\"chapter \", chapter)                           \n",
    "                                text_dict[liber][chapter].append([year, typeof, process_vrt(raw_text)])\n",
    "                                \n",
    "                                \n",
    "                    \n",
    "            #chapters under liber 0-1\n",
    "            elif ell.attrib[\"class\"] == \"chapter\":\n",
    "                if chapter is not None:\n",
    "                    chapter += 1\n",
    "                else:\n",
    "                    chapter = 0\n",
    "                text_dict[liber][chapter] = list()\n",
    "                for elll in ell.getchildren():\n",
    "                    typeof = check_type(elll)\n",
    "                    raw_text = elll.text\n",
    "                    text_dict[liber][chapter].append([year, typeof, process_vrt(raw_text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f21f290-385f-4ded-af93-d0ab74a231b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_dict = {} #{book : {chapter : [{year, typeof, txt}]} }\n",
    "liber = 0\n",
    "for el in root: #liber\n",
    "    year = 0\n",
    "    chapter = None\n",
    "    classes = ['head', 'annus', 'text']\n",
    "    typeof = 'text'\n",
    "    raw_text = ''\n",
    "    \n",
    "    #liber\n",
    "    if \"class\" in el.attrib.keys():\n",
    "        if el.attrib[\"class\"] == 'liber':\n",
    "            liber = int(el.attrib[\"n\"])\n",
    "            text_dict[liber] = dict()\n",
    "            #print(\"liber\",liber)\n",
    "    for ell in el.getchildren():\n",
    "        if \"class\" in el.attrib.keys():\n",
    "            if ell.attrib[\"class\"] == \"year\":\n",
    "                year = ell.attrib[\"n\"]\n",
    "                #print(\"year \", year)\n",
    "                for elll in ell.getchildren():\n",
    "                    if elll.tag == \"head\":\n",
    "                        typeof = check_type(elll)                \n",
    "                        raw_text = elll.text\n",
    "                        if chapter is not None:\n",
    "                            chapter += 1\n",
    "                        else:\n",
    "                            chapter = 0\n",
    "                        text_dict[liber][chapter] = list()\n",
    "                        text_dict[liber][chapter].append([year, typeof, process_vrt(raw_text)])\n",
    "                            \n",
    "                    elif elll.tag == \"div\":\n",
    "                        if elll.attrib[\"class\"] == \"chapter\":\n",
    "                            if chapter is not None:\n",
    "                                chapter += 1\n",
    "                            else:\n",
    "                                chapter = 0\n",
    "                            #print(\"chapter \", chapter)\n",
    "                            text_dict[liber][chapter] = list()\n",
    "                            for ellll in elll.getchildren():\n",
    "                                typeof = check_type(ellll)\n",
    "                                raw_text = ellll.text\n",
    "                                #print(\"chapter \", chapter)                           \n",
    "                                text_dict[liber][chapter].append([year, typeof, process_vrt(raw_text)])\n",
    "            #chapters under liber 0-1\n",
    "            elif ell.attrib[\"class\"] == \"chapter\":\n",
    "                if chapter is not None:\n",
    "                    chapter += 1\n",
    "                else:\n",
    "                    chapter = 0\n",
    "                text_dict[liber][chapter] = list()\n",
    "                for elll in ell.getchildren():\n",
    "                    typeof = check_type(elll)\n",
    "                    raw_text = elll.text\n",
    "                    text_dict[liber][chapter].append([year, typeof, process_vrt(raw_text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6600f929-493e-452a-ab37-257e05452cea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs_by_year = [] \n",
    "docs_by_liber = []\n",
    "docs_by_chapter = [] # list of chapters (liber, chapter, year, tokens)\n",
    "all_by_chapter= [] #all chaps\n",
    "txt_chapt_numbers = []\n",
    "txt_chapt_num_current = []\n",
    "text_to_all_chapters = {} #{chapter : {liber:chapter}} #only texts\n",
    "text_dict_joined = {}\n",
    "\n",
    "i = 0\n",
    "for liber in text_dict.keys():\n",
    "    if liber not in text_dict_joined.keys():\n",
    "        text_dict_joined[liber] = {}\n",
    "    for chapter in text_dict[liber].keys():\n",
    "        if chapter not in text_dict_joined[liber].keys():\n",
    "            text_dict_joined[liber][chapter] = {\"year\":None}\n",
    "            \n",
    "        \n",
    "        chapter_tokens_txt = []\n",
    "        chapter_tokens = []\n",
    "        \n",
    "        for txt_arr in text_dict[liber][chapter]:\n",
    "            text_dict_joined[liber][chapter][\"year\"] = txt_arr[0]\n",
    "            if txt_arr[1] not in text_dict_joined[liber][chapter].keys():\n",
    "                text_dict_joined[liber][chapter][txt_arr[1]] = []\n",
    "            text_dict_joined[liber][chapter][txt_arr[1]].append(' '.join([tok[0] for tok in txt_arr[2]]))\n",
    "            for tok in txt_arr[2]: #iterates over tokens\n",
    "                chapter_tokens.append((liber, chapter, txt_arr[0], txt_arr[1], tok[0], tok[1], tok[2])) #liber,chap, year,token\n",
    "            \n",
    "            if txt_arr[1] == \"text\": #exclude head etc.\n",
    "                if str(liber) + \"_\" + str(chapter) not in txt_chapt_num_current:\n",
    "                    txt_chapt_num_current.append(str(liber) + \"_\" + str(chapter))\n",
    "                    text_to_all_chapters[i] = {liber:chapter}\n",
    "                    i+= 1\n",
    "                for tok in txt_arr[2]: #iterates over tokens\n",
    "                    chapter_tokens_txt.append((liber, chapter, txt_arr[0], tok[0], tok[1], tok[2])) #liber,chap, year,token\n",
    "        if len(chapter_tokens_txt) > 0:\n",
    "            docs_by_chapter.append(chapter_tokens_txt)\n",
    "        all_by_chapter.append(chapter_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d1c981f-93e9-4880-94a3-e22207efc978",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corpus_chapters = []\n",
    "corpus_chapters_lemmas = [] #no uknown\n",
    "corpus_chapters_lemmas_all = []\n",
    "corpus_chapters_lemmas_year = []\n",
    "year = 0\n",
    "for chap in docs_by_chapter:\n",
    "    doc = []\n",
    "    doc_lemmas = []\n",
    "    doc_lemmas_all = []\n",
    "    \n",
    "    for tok in chap:\n",
    "        if tok[4] not in [\"PUN\", \"SENT\"]:\n",
    "            doc.append(tok[3].lower())            \n",
    "            if tok[5] is not None and tok[5] != 'UNKNOWN':\n",
    "                doc_lemmas.append(tok[5].lower())\n",
    "                year = tok[2]\n",
    "            elif tok[5] is not None:\n",
    "                if tok[5] == 'UNKNOWN':\n",
    "                    doc_lemmas_all.append(tok[3].lower())\n",
    "                else:\n",
    "                    doc_lemmas_all.append(tok[5].lower())\n",
    "    corpus_chapters_lemmas_year.append(year)\n",
    "    corpus_chapters.append(doc)\n",
    "    corpus_chapters_lemmas.append(doc_lemmas)\n",
    "    corpus_chapters_lemmas_all.append(doc_lemmas_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74eed6f5-aa6d-4b39-b4bd-facd4d5e84e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corpus_chapters_lemmas_reduced = []\n",
    "stoplist_lemma = [\"-\", \"major\", \"nemo\", \"aliter\", \"nisi\", \"verum\", \"quis\", \"per\", \"vir\", \"teneo\", \"saltim\", \"velut\", \"ita\", \n",
    "                  \"quis\", \"do\", \"etenim\", \"vix\", \"bene\", \"vel\",\"facio|fio\", \"quoniam\", \"se\", \"a\", \"de\", \"cum\",\"tuus\", \n",
    "                  \"omnis\", \"ex\", \"sive\", \"post\", \"ego\", \"tu\", \"non\", \"quia\", \"eo\", \"sum\", \"qui\", \"ut\", \"ac\", \"is\", \n",
    "                  \"ille\",\"ad\",\"in\",\"et\",\"sed\", \"que\", \"deus\", \"tam\", \"hic\", \"homo\", \"tempus\", \"aut\", \"atque\", \"habeo\",\n",
    "                  \"dum\", \"unus\", \"ipse\", \"nec\", \"quoque\", \"adeo\", \"aput\", \"alius\", \"nullus\", \"enim\", \"genus\", \"autem\", \n",
    "                  \"quidem\", \"res\", \"mille\", \"si\", \"plus\", \"possum\", \"tamen\", \"ubi\", \"sed\", \"multus\", \"idem\", \"tunc\",\n",
    "                  \"propter\", \"fero\", \"tam\", \"ne\", \"noster\", \"nos\", \"dominus\", \"ago\", \"contra\", \"res\", \"inter\", \"etiam\", \n",
    "                  \"sub\", \"duo\", \"tres\", \"septem\", \"quattuor\", \"quinque\", \"sex\", \"septem\", \"octo\", \"novem\", \"decem\", \n",
    "                  \"viginti\", \"ceterus\", \"annus\", \"circa\", \"homo\", \"ab\", \"sus\", \"insuper\", \"ab\", \"suus\", \"pro\", \"alter\", \"seu\", \"item\", \"quidam\",\n",
    "                 \"magis\", \"facio\", \"dico\", \"appello\", \"itaque\", \"jam\", \"credo\", \"dies\", \"magis\", \"siquidem\"]\n",
    "for chapter in corpus_chapters_lemmas:\n",
    "    corpus_chapters_lemmas_reduced.append([tok for tok in chapter if tok not in stoplist_lemma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46fc5520-160c-4d8b-b466-748805da64d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# serialization\n",
    "import pickle\n",
    "with open(\"corpora/corpus_chapters\", \"wb\") as f:\n",
    "    pickle.dump(corpus_chapters, f)\n",
    "\n",
    "with open(\"corpora/corpus_chapters_lemmas\", \"wb\") as f:\n",
    "    pickle.dump(corpus_chapters_lemmas, f)\n",
    "\n",
    "with open(\"corpora/corpus_chapters_lemmas_reduced\", \"wb\") as f:\n",
    "    pickle.dump(corpus_chapters_lemmas_reduced, f)\n",
    "    \n",
    "with open(\"corpora/text_to_all_chapters\", \"wb\") as f:\n",
    "    pickle.dump(text_to_all_chapters, f)\n",
    "\n",
    "with open(\"corpora/text_dict_joined\", \"wb\") as f:\n",
    "    pickle.dump(text_dict_joined, f)\n",
    "    \n",
    "with open(\"corpora/docs_by_chapter\", \"wb\") as f:\n",
    "    pickle.dump(docs_by_chapter, f)\n",
    "with open(\"corpora/docs_by_year\", \"wb\") as f:\n",
    "    pickle.dump(docs_by_year, f)\n",
    "with open(\"corpora/docs_by_liber\", \"wb\") as f:\n",
    "    pickle.dump(docs_by_liber, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
